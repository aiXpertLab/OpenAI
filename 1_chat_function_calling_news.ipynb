{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3a7f868-81f4-4f78-82e2-6cee216c5c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import tiktoken\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "\n",
    "llm_model = \"gpt-3.5-turbo-1106\"\n",
    "llm_max_tokens = 155\n",
    "llm_system_prompt = \"You are an assistant that provides news and headlines to user requests. Always try to get the lastest breaking stories using the available function calls.\"\n",
    "encoding_model_messages = \"gpt-3.5-turbo-1106\"\n",
    "encoding_model_strings = \"cl100k_base\"\n",
    "function_call_limit = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71edacfc-c422-412a-a67a-f6c08ddd482d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages):\n",
    "    \"\"\"Returns the number of tokens used by a list of messages.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(encoding_model_messages)\n",
    "    except KeyError:\n",
    "        encoding = tiktoken.get_encoding(encoding_model_strings)\n",
    "\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += 4\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(str(value)))\n",
    "            if key == \"name\":\n",
    "                num_tokens += -1\n",
    "    num_tokens += 2\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed6a8c1b-06b9-4004-ba9b-d37756bf06c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_headlines(query: str = None, country: str = None, category: str = None):\n",
    "    \"\"\"Retrieve top headlines from newsapi.org (API key required)\"\"\"\n",
    "\n",
    "    base_url = \"https://newsapi.org/v2/top-headlines\"\n",
    "    headers = {\n",
    "        \"x-api-key\": os.environ['NEWS_API_KEY']\n",
    "    }\n",
    "    params = { \"category\": \"general\" }\n",
    "    if query is not None:\n",
    "        params['q'] = query\n",
    "    if country is not None:\n",
    "        params['country'] = country\n",
    "    if category is not None:\n",
    "        params['category'] = category\n",
    "\n",
    "    # Fetch from newsapi.org - reference: https://newsapi.org/docs/endpoints/top-headlines\n",
    "    response = requests.get(base_url, params=params, headers=headers)\n",
    "    data = response.json()\n",
    "\n",
    "    if data['status'] == 'ok':\n",
    "        print(f\"Processing {data['totalResults']} articles from newsapi.org\")\n",
    "        return json.dumps(data['articles'])\n",
    "    else:\n",
    "        print(\"Request failed with message:\", data['message'])\n",
    "        return 'No articles found'\n",
    "\n",
    "signature_get_top_headlines = {\n",
    "    \"name\": \"get_top_headlines\",\n",
    "    \"description\": \"Get top news headlines by country and/or category\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"query\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Freeform keywords or a phrase to search for.\",\n",
    "            },\n",
    "            \"country\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The 2-letter ISO 3166-1 code of the country you want to get headlines for\",\n",
    "            },\n",
    "            \"category\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The category you want to get headlines for\",\n",
    "                \"enum\": [\"business\",\"entertainment\",\"general\",\"health\",\"science\",\"sports\",\"technology\"]\n",
    "            }\n",
    "        },\n",
    "        \"required\": [],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0910279-2a5d-4242-a630-8327dc59db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(messages, function_call: str = \"auto\"):\n",
    "    \"\"\"Fetch completion from OpenAI's GPT\"\"\"\n",
    "\n",
    "    messages.append({\"role\": \"system\", \"content\": llm_system_prompt})\n",
    "\n",
    "    # delete older completions to keep conversation under token limit\n",
    "    while num_tokens_from_messages(messages) >= llm_max_tokens:\n",
    "        messages.pop(0)\n",
    "\n",
    "    print('Working...')\n",
    "    \n",
    "    res = client.chat.completions.create(\n",
    "        model=llm_model,\n",
    "        messages=messages,\n",
    "        functions=[signature_get_top_headlines],\n",
    "        function_call=function_call\n",
    "    )\n",
    "\n",
    "    # remove system message and append response from the LLM\n",
    "    messages.pop(-1)\n",
    "    response = res[\"choices\"][0][\"message\"]\n",
    "    messages.append(response)\n",
    "\n",
    "    # call functions requested by the model\n",
    "    if response.get(\"function_call\"):\n",
    "        function_name = response[\"function_call\"][\"name\"]\n",
    "        if function_name == \"get_top_headlines\":\n",
    "            args = json.loads(response[\"function_call\"][\"arguments\"])\n",
    "            headlines = get_top_headlines(\n",
    "                query=args.get(\"query\"),\n",
    "                country=args.get(\"country\"),\n",
    "                category=args.get(\"category\")        \n",
    "            )\n",
    "            messages.append({ \"role\": \"function\", \"name\": \"get_top_headline\", \"content\": headlines})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446ca7fc-cd34-49f6-bb4d-e33872a4caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nHi, I'm a NewsGPT, a breaking news AI assistant. I can give you news for most countries over a wide range of categories.\")\n",
    "print(\"Here are some example prompts:\\n - Tell me about the recent science discoveries\\n - What is the latest news in the US?\\n - What has Elon Musk been up to recently?\")\n",
    "\n",
    "messages = []\n",
    "while True:\n",
    "    prompt = input(\"\\nWhat would you like to know? => \")\n",
    "    messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "    complete(messages)\n",
    "\n",
    "    # the LLM can chain function calls, this implements a limit\n",
    "    call_count = 0\n",
    "    while messages[-1]['role'] == \"function\":\n",
    "        call_count = call_count + 1\n",
    "        if call_count < function_call_limit:\n",
    "            complete(messages)\n",
    "        else:\n",
    "            complete(messages, function_call=\"none\")\n",
    "\n",
    "    # print last message\n",
    "    print(\"\\n\\n==Response==\\n\")\n",
    "    print(messages[-1][\"content\"].strip())\n",
    "    print(\"\\n==End of response==\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
